{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP90049 Introduction to Machine Learning, 2020 Semester 1\n",
    "-----\n",
    "## Project 1: Understanding Student Success with Naive Bayes\n",
    "-----\n",
    "###### Student Name(s):\n",
    "###### Python version:\n",
    "###### Submission deadline: 11am, Wed 22 Apr 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Project 1 submission. \n",
    "\n",
    "Marking will be applied on the five functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 is found below\n",
    "## 1) Part A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1) Part B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n",
      "  school sex address famsize Pstatus  Medu  Fedu      Mjob      Fjob  reason  \\\n",
      "0     GP   M       U     GT3       T  high  high  services   teacher    home   \n",
      "1     MS   M       R     GT3       T   mid   mid     other     other  course   \n",
      "2     GP   F       R     LE3       T   mid   mid  services  services  course   \n",
      "\n",
      "   ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "0  ...      yes       no      5        2     3    1    2      5   \n",
      "1  ...      yes       no      2        5     5    5    5      5   \n",
      "2  ...      yes       no      3        3     2    2    2      3   \n",
      "\n",
      "        absences Grade  \n",
      "0    four_to_six     B  \n",
      "1  more_than_ten     D  \n",
      "2           none     D  \n",
      "\n",
      "[3 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"student.csv\"\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "rawData = load_data(path)\n",
    "print(len(rawData))\n",
    "print(rawData.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex address famsize Pstatus  Medu  Fedu     Mjob     Fjob  reason  \\\n",
      "229     MS   F       U     LE3       T  high  high  at_home  at_home  course   \n",
      "321     MS   F       U     GT3       T   low   mid    other    other  course   \n",
      "517     GP   F       U     GT3       T  high  high   health   health  course   \n",
      "\n",
      "     ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "229  ...      yes      yes      2        3     4    1    1      1   \n",
      "321  ...      yes      yes      3        4     4    2    3      5   \n",
      "517  ...      yes       no      5        3     4    1    2      5   \n",
      "\n",
      "          absences Grade  \n",
      "229    four_to_six     B  \n",
      "321  more_than_ten     F  \n",
      "517   one_to_three     A  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "    school sex address famsize Pstatus  Medu  Fedu      Mjob    Fjob  \\\n",
      "590     GP   M       R     LE3       A  high  high   teacher   other   \n",
      "237     GP   M       U     LE3       T   mid   mid  services  health   \n",
      "\n",
      "         reason  ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "590      course  ...      yes       no      3        3     3    2    3      4   \n",
      "237  reputation  ...      yes       no      4        3     4    1    1      4   \n",
      "\n",
      "         absences Grade  \n",
      "590          none     C  \n",
      "237  one_to_three     C  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This function should split a data set into a training set and hold-out test set\n",
    "def split_data(rawData):\n",
    "#     return rawData, rawData\n",
    "    return train_test_split(rawData, test_size=0.1)\n",
    "\n",
    "trainData, testData = split_data(rawData)\n",
    "print(trainData.head(3))\n",
    "print(testData.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n",
      "     A+  A  B   C   D  F\n",
      "GP  NaN  5  8  13  13  3\n",
      "MS    1  4  1   2   8  7\n",
      "\n",
      "sex\n",
      "    A+  A  B  C   D  F\n",
      "M  NaN  2  2  7  10  2\n",
      "F    1  7  7  8  11  8\n",
      "\n",
      "address\n",
      "    A+  A    B   C   D  F\n",
      "U    1  5    9  11  13  6\n",
      "R  NaN  4  NaN   4   8  4\n",
      "\n",
      "famsize\n",
      "      A+  A  B  C   D  F\n",
      "GT3    1  7  8  9  16  7\n",
      "LE3  NaN  2  1  6   5  3\n",
      "\n",
      "Pstatus\n",
      "    A+    A    B  C   D  F\n",
      "T    1    9    9  9  18  9\n",
      "A  NaN  NaN  NaN  6   3  1\n",
      "\n",
      "Medu\n",
      "       A+    A    B    C   D    F\n",
      "high    1    5    4    5   4  NaN\n",
      "mid   NaN    4    5    5  12    6\n",
      "low   NaN  NaN  NaN    5   4    4\n",
      "none  NaN  NaN  NaN  NaN   1  NaN\n",
      "\n",
      "Fedu\n",
      "       A+    A    B  C   D    F\n",
      "high  NaN    5    1  5   1    1\n",
      "mid     1    4    5  5  12    5\n",
      "low   NaN  NaN    3  4   7    4\n",
      "none  NaN  NaN  NaN  1   1  NaN\n",
      "\n",
      "Mjob\n",
      "           A+    A  B  C  D    F\n",
      "services  NaN    1  3  3  3    2\n",
      "other     NaN    4  2  4  8    6\n",
      "teacher     1    3  2  3  2  NaN\n",
      "at_home   NaN  NaN  1  4  6    2\n",
      "health    NaN    1  1  1  2  NaN\n",
      "\n",
      "Fjob\n",
      "           A+    A    B    C    D    F\n",
      "teacher   NaN    2    1    1  NaN  NaN\n",
      "other       1    4    5    9   14    7\n",
      "services  NaN    3    2    4    6    2\n",
      "health    NaN  NaN  NaN    1  NaN  NaN\n",
      "at_home   NaN  NaN    1  NaN    1    1\n",
      "\n",
      "reason\n",
      "             A+  A  B    C   D    F\n",
      "home        NaN  1  2    7   5    3\n",
      "course        1  1  3    3  12    4\n",
      "other       NaN  2  1  NaN   3    3\n",
      "reputation  NaN  5  3    5   1  NaN\n",
      "\n",
      "guardian\n",
      "         A+    A  B    C   D  F\n",
      "mother  NaN    7  6   13  18  8\n",
      "father    1    2  2    2   2  1\n",
      "other   NaN  NaN  1  NaN   1  1\n",
      "\n",
      "traveltime\n",
      "            A+    A    B   C  D  F\n",
      "low        NaN    6    5  10  9  7\n",
      "medium       1    3    4   2  7  1\n",
      "high       NaN  NaN  NaN   1  3  1\n",
      "very_high  NaN  NaN  NaN   2  2  1\n",
      "\n",
      "studytime\n",
      "            A+    A    B  C   D    F\n",
      "low        NaN    1    2  4  12    6\n",
      "high       NaN    3    2  3   2    2\n",
      "medium     NaN    5    5  6   6    2\n",
      "very_high    1  NaN  NaN  2   1  NaN\n",
      "\n",
      "failures\n",
      "         A+    A    B    C    D    F\n",
      "none      1    9    9   15   16    5\n",
      "low     NaN  NaN  NaN  NaN    5    4\n",
      "medium  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "high    NaN  NaN  NaN  NaN  NaN    1\n",
      "\n",
      "schoolsup\n",
      "      A+    A    B   C   D  F\n",
      "no     1    9    9  12  18  8\n",
      "yes  NaN  NaN  NaN   3   3  2\n",
      "\n",
      "famsup\n",
      "      A+  A  B   C   D  F\n",
      "no     1  5  5   5   9  3\n",
      "yes  NaN  4  4  10  12  7\n",
      "\n",
      "paid\n",
      "      A+    A    B   C   D  F\n",
      "no     1    9    9  13  19  9\n",
      "yes  NaN  NaN  NaN   2   2  1\n",
      "\n",
      "activities\n",
      "      A+  A  B  C   D  F\n",
      "no     1  4  2  7  14  9\n",
      "yes  NaN  5  7  8   7  1\n",
      "\n",
      "nursery\n",
      "      A+  A  B   C   D  F\n",
      "yes    1  8  8  13  15  7\n",
      "no   NaN  1  1   2   6  3\n",
      "\n",
      "higher\n",
      "      A+    A    B    C   D  F\n",
      "yes    1    9    9   15  18  8\n",
      "no   NaN  NaN  NaN  NaN   3  2\n",
      "\n",
      "internet\n",
      "      A+  A  B   C   D  F\n",
      "yes    1  7  8  10  14  9\n",
      "no   NaN  2  1   5   7  1\n",
      "\n",
      "romantic\n",
      "      A+  A  B   C   D  F\n",
      "no   NaN  5  5  10  16  8\n",
      "yes    1  4  4   5   5  2\n",
      "\n",
      "famrel\n",
      "    A+    A    B    C    D    F\n",
      "5  NaN    4    1    4    6    6\n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "3  NaN  NaN    1    2    2    1\n",
      "4    1    4    6    8   13    2\n",
      "1  NaN    1    1    1  NaN    1\n",
      "\n",
      "freetime\n",
      "    A+    A    B    C  D    F\n",
      "2    1    2    2    1  4  NaN\n",
      "5  NaN  NaN  NaN  NaN  4    3\n",
      "3  NaN    3    5    9  6    3\n",
      "1  NaN  NaN    1    4  1    1\n",
      "4  NaN    4    1    1  6    3\n",
      "\n",
      "goout\n",
      "    A+    A    B  C    D    F\n",
      "3    1    2  NaN  5    7    2\n",
      "5  NaN  NaN    2  1    5    2\n",
      "2  NaN    5    4  3    5    4\n",
      "4  NaN    2    3  4    4    2\n",
      "1  NaN  NaN  NaN  2  NaN  NaN\n",
      "\n",
      "Dalc\n",
      "    A+    A    B    C    D    F\n",
      "1  NaN    5    7   12   15    7\n",
      "5  NaN  NaN  NaN    1  NaN  NaN\n",
      "2  NaN    4    2    1    2    2\n",
      "3    1  NaN  NaN    1    3    1\n",
      "4  NaN  NaN  NaN  NaN    1  NaN\n",
      "\n",
      "Walc\n",
      "    A+    A    B  C  D    F\n",
      "2  NaN    2    3  1  4    3\n",
      "5  NaN  NaN  NaN  1  2  NaN\n",
      "3  NaN    3    1  2  3    2\n",
      "1    1    3    5  9  9    3\n",
      "4  NaN    1  NaN  2  3    2\n",
      "\n",
      "health\n",
      "    A+    A    B  C   D    F\n",
      "5    1    4    3  5  10    6\n",
      "3  NaN  NaN    1  4   4    2\n",
      "1  NaN    4    3  1   2  NaN\n",
      "4  NaN  NaN  NaN  4   4    1\n",
      "2  NaN    1    2  1   1    1\n",
      "\n",
      "absences\n",
      "                A+  A  B  C  D  F\n",
      "four_to_six    NaN  1  2  3  7  1\n",
      "more_than_ten  NaN  1  2  3  1  1\n",
      "none             1  5  4  5  8  4\n",
      "one_to_three   NaN  2  1  4  5  4\n",
      "\n",
      "Grade\n",
      "     A+    A    B    C    D    F\n",
      "A+    1  NaN  NaN  NaN  NaN  NaN\n",
      "A   NaN    9  NaN  NaN  NaN  NaN\n",
      "B   NaN  NaN    9  NaN  NaN  NaN\n",
      "C   NaN  NaN  NaN   15  NaN  NaN\n",
      "D   NaN  NaN  NaN  NaN   21  NaN\n",
      "F   NaN  NaN  NaN  NaN  NaN   10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "featureFrames = []\n",
    "CLASSES = [\"A+\", \"A\",\"B\",\"C\",\"D\",\"F\"]\n",
    "\n",
    "\n",
    "def make_grade_struct():\n",
    "    featureFrames[len(list(rawData))-1] = pd.DataFrame(columns=CLASSES, index=CLASSES)\n",
    "\n",
    "def make_data_structs():\n",
    "    paramNames = []\n",
    "\n",
    "    #For each feature\n",
    "    for feature in list(rawData):\n",
    "#         print(feature)\n",
    "        \n",
    "        #Find all the names of the paramaters by iterating through all data\n",
    "        for j in range(len(rawData)):\n",
    "            if str(rawData[feature][j]) not in paramNames:\n",
    "                paramNames.append(str(rawData[feature][j]))        \n",
    "        \n",
    "        #Make a dataframe to store frequency information with format:     \n",
    "        #     A+    A    B    C    D    F\n",
    "        # T  NaN  NaN  NaN  NaN  NaN  NaN\n",
    "        # A  NaN  NaN  NaN  NaN  NaN  NaN\n",
    "        \n",
    "        df = pd.DataFrame(columns=CLASSES, index=paramNames)\n",
    "        featureFrames.append(df.copy())\n",
    "#         print(df)\n",
    "#         print()\n",
    "\n",
    "        #Reset paramNames \n",
    "        paramNames = []\n",
    "        \n",
    "    #In case we don't see all the grade values, do this manually \n",
    "    make_grade_struct()    \n",
    "    \n",
    "def count_param_freq(data):\n",
    "    #For every feature\n",
    "    for i, feature in enumerate(list(data)):\n",
    "        \n",
    "        #Go and count the number of times each paramater resulted in what grade\n",
    "        for j in range(len(data)):\n",
    "\n",
    "            #Define the parameter feature, grade, and position in data struct\n",
    "            param = str(data[feature].iloc[j])\n",
    "            grade = data[\"Grade\"].iloc[j]\n",
    "            freqCount = featureFrames[i][grade][param]\n",
    "        \n",
    "            #Count the number of times that this parameter is seen\n",
    "            if pd.isnull(freqCount):\n",
    "                featureFrames[i][grade][param] = 1\n",
    "            else:\n",
    "                featureFrames[i][grade][param]+=1\n",
    "                \n",
    "                \n",
    "        print(feature)\n",
    "        print(featureFrames[i])\n",
    "        print()\n",
    "\n",
    "            \n",
    "            \n",
    " \n",
    "\n",
    "# This function should build a supervised NB model\n",
    "def train(data):\n",
    "    make_data_structs()\n",
    "    count_param_freq(data)\n",
    "    return\n",
    "\n",
    "\n",
    "train(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance number 0 is predicted to be = C, actual grade = C\n",
      "instance number 1 is predicted to be = C, actual grade = C\n",
      "instance number 2 is predicted to be = A, actual grade = A\n",
      "instance number 3 is predicted to be = D, actual grade = D\n",
      "instance number 4 is predicted to be = A, actual grade = A\n",
      "instance number 5 is predicted to be = D, actual grade = D\n",
      "instance number 6 is predicted to be = F, actual grade = F\n",
      "instance number 7 is predicted to be = F, actual grade = F\n",
      "instance number 8 is predicted to be = A, actual grade = A\n",
      "instance number 9 is predicted to be = F, actual grade = F\n",
      "instance number 10 is predicted to be = D, actual grade = D\n",
      "instance number 11 is predicted to be = A, actual grade = A\n",
      "instance number 12 is predicted to be = C, actual grade = C\n",
      "instance number 13 is predicted to be = B, actual grade = C\n",
      "instance number 14 is predicted to be = B, actual grade = B\n",
      "instance number 15 is predicted to be = A, actual grade = A\n",
      "instance number 16 is predicted to be = F, actual grade = C\n",
      "instance number 17 is predicted to be = F, actual grade = D\n",
      "instance number 18 is predicted to be = F, actual grade = F\n",
      "instance number 19 is predicted to be = D, actual grade = D\n",
      "instance number 20 is predicted to be = B, actual grade = B\n",
      "instance number 21 is predicted to be = F, actual grade = D\n",
      "instance number 22 is predicted to be = A, actual grade = D\n",
      "instance number 23 is predicted to be = C, actual grade = A\n",
      "instance number 24 is predicted to be = A, actual grade = A\n",
      "instance number 25 is predicted to be = A+, actual grade = A+\n",
      "instance number 26 is predicted to be = F, actual grade = D\n",
      "instance number 27 is predicted to be = C, actual grade = C\n",
      "instance number 28 is predicted to be = C, actual grade = C\n",
      "instance number 29 is predicted to be = C, actual grade = C\n",
      "instance number 30 is predicted to be = D, actual grade = D\n",
      "instance number 31 is predicted to be = F, actual grade = F\n",
      "instance number 32 is predicted to be = D, actual grade = D\n",
      "instance number 33 is predicted to be = D, actual grade = D\n",
      "instance number 34 is predicted to be = B, actual grade = A\n",
      "instance number 35 is predicted to be = C, actual grade = C\n",
      "instance number 36 is predicted to be = B, actual grade = B\n",
      "instance number 37 is predicted to be = B, actual grade = B\n",
      "instance number 38 is predicted to be = B, actual grade = B\n",
      "instance number 39 is predicted to be = F, actual grade = F\n",
      "instance number 40 is predicted to be = F, actual grade = F\n",
      "instance number 41 is predicted to be = D, actual grade = D\n",
      "instance number 42 is predicted to be = D, actual grade = D\n",
      "instance number 43 is predicted to be = D, actual grade = D\n",
      "instance number 44 is predicted to be = B, actual grade = B\n",
      "instance number 45 is predicted to be = C, actual grade = C\n",
      "instance number 46 is predicted to be = B, actual grade = B\n",
      "instance number 47 is predicted to be = C, actual grade = D\n",
      "instance number 48 is predicted to be = D, actual grade = D\n",
      "instance number 49 is predicted to be = C, actual grade = D\n",
      "instance number 50 is predicted to be = B, actual grade = B\n",
      "instance number 51 is predicted to be = C, actual grade = D\n",
      "instance number 52 is predicted to be = D, actual grade = D\n",
      "instance number 53 is predicted to be = C, actual grade = C\n",
      "instance number 54 is predicted to be = D, actual grade = D\n",
      "instance number 55 is predicted to be = F, actual grade = F\n",
      "instance number 56 is predicted to be = C, actual grade = C\n",
      "instance number 57 is predicted to be = B, actual grade = B\n",
      "instance number 58 is predicted to be = A, actual grade = A\n",
      "instance number 59 is predicted to be = F, actual grade = F\n",
      "instance number 60 is predicted to be = C, actual grade = C\n",
      "instance number 61 is predicted to be = D, actual grade = D\n",
      "instance number 62 is predicted to be = C, actual grade = C\n",
      "instance number 63 is predicted to be = F, actual grade = F\n",
      "instance number 64 is predicted to be = C, actual grade = C\n",
      "0.015384615384615385\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import random\n",
    "\n",
    "eps = None\n",
    "totTrainingRows = None\n",
    "\n",
    "\n",
    "def find_probability(testGrade, testInst):\n",
    "\n",
    "    #P(label|params) = const * p(param1|label) * p(param2|label) * ...\n",
    "    probability = 1\n",
    "    \n",
    "    #For every parameter, find the probability and update main prob\n",
    "    #for every feature name\n",
    "    for i, label in enumerate(rawData):\n",
    "        #Don't use the \"Grade\" column for the instance\n",
    "        if i == len(list(rawData))-1:\n",
    "            break\n",
    "            \n",
    "\n",
    "        # p(param1|label) = numberParam1|label / numberOfLabel\n",
    "        #Get the actual paramater we're finding the probability of\n",
    "        testParam = str(testInst[label])\n",
    "        \n",
    "        #Number of times this prameter was counted in training given the label\n",
    "        try:\n",
    "            #Try find the label, if you can't find it, or the value is null, probability *= eps\n",
    "            paramFreq = featureFrames[i][testGrade][testParam]       \n",
    "            if pd.isnull(paramFreq):\n",
    "                probability*=eps\n",
    "                continue\n",
    "        except:\n",
    "            probability*=eps\n",
    "            continue\n",
    "\n",
    "        \n",
    "        #The number of times this grade has been counted in training\n",
    "        gradeFreq = featureFrames[len(featureFrames)-1][testGrade][testGrade]            \n",
    "        \n",
    "#         print(\"Our instance where {}={}, according to main data=\\n {}, \\n has freq={}, with {} freq = {} with data= \\n {}\".format(label, testParam, featureFrames[i], paramFreq, testGrade, labelFreq, featureFrames[len(featureFrames)-1]))\n",
    "        #Update probability\n",
    "        probability *= (paramFreq/gradeFreq)\n",
    "\n",
    "    probability *= gradeFreq/totTrainingRows\n",
    "#     print(probability)\n",
    "#     print()\n",
    "\n",
    "    return probability\n",
    "\n",
    "def predict_grade(instance):\n",
    "    labelProbability = {\"A+\":0,\"A\":0,\"B\":0,\"C\":0,\"D\":0,\"F\":0}\n",
    "    \n",
    "    #For every potential label (A+, A, B, C, D, F), find P(label|params)\n",
    "    for label in labelProbability.keys():\n",
    "        labelProbability[label] = find_probability(label, instance)  \n",
    "    \n",
    "#     print(\"Calculated probabilities = {}\".format(labelProbability))\n",
    "    return max(labelProbability.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "\n",
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(data):\n",
    "    global eps\n",
    "    global totTrainingRows\n",
    "    eps = 1/len(data)\n",
    "    totTrainingRows = len(data)    \n",
    "    \n",
    "    for i, inst in enumerate(data.iterrows()):\n",
    "        print(\"instance number {} is predicted to be = {}, actual grade = {}\".format(i, predict_grade(inst[1]), inst[1][\"Grade\"]))\n",
    "    \n",
    "\n",
    "\n",
    "predict(testData)\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.8307692307692308. (54 successes and 11 fails)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = {\"success\":0, \"fail\":0}\n",
    "\n",
    "# This function should evaluate a set of predictions in terms of accuracy\n",
    "def evaluate(data):\n",
    "    for inst in data.iterrows():\n",
    "#         print(\"instance number {} is predicted to be = {}, actual grade = {}\".format(i, find_grade(inst[1]), inst[1][\"Grade\"]))\n",
    "        if(predict_grade(inst[1]) == inst[1][\"Grade\"]):\n",
    "            accuracy[\"success\"] += 1\n",
    "        else:\n",
    "            accuracy[\"fail\"] += 1\n",
    "    s = accuracy[\"success\"]\n",
    "    f = accuracy[\"fail\"]\n",
    "    print(\"accuracy is {}. ({} successes and {} fails)\".format((s/(s+f)), s, f))\n",
    "            \n",
    "    return\n",
    "\n",
    "evaluate(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Part C\n",
    "kjnsdfknjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "### Question 2: A Closer Look at Evaluation\n",
    "\n",
    "- a You learnt in the lectures that precision, recall and f-1 measure can provide a more holistic and realistic picture of the classifier performance. (i) Explain the intuition behind accuracy, precision, recall, and F1-measure, (ii) contrast their utility, and (iii) discuss the difference between micro and macro averaging in the context of the data set. [no programming required]\n",
    "- b Compute precision, recall and f-1 measure of your model’s predictions on the test data set (1) separately for each class, and (2) as a single number using macro-averaging. Compare the results against your accuracy scores from Question 1. In the context of the student dataset, and your response to question 2a analyze the additional knowledge you gained about your classifier performance.\n",
    "\n",
    "\n",
    "\n",
    "#### a)\n",
    "Accuracy - This is the proportion of guesses we got right compared to all guesses. More formally:\n",
    "\n",
    "(True positives + True Negatives)/(True or Flase positives or negatives)\n",
    "\n",
    "\n",
    "Precision - With respect to a class that we care to measure (maybe A+ students in this example), how often is our model correct. If we really care about one label more than the others, we want to see how accurately we can predict that class. More formally:\n",
    "\n",
    "(True positives)/(True or False positives)\n",
    "\n",
    "\n",
    "Recall - How good is our model at detecting our desired class. More formally:\n",
    "\n",
    "(True positives)/(True positives + False Negatives)\n",
    "\n",
    "\n",
    "F1 measure - A combined measure of precision and recall using the harmonic mean. This is important because precision and recall are usually inversely correlated (models with higher recall have lower precisino and vice versa). It is defined:\n",
    "\n",
    "(2 * Precision*Recall)/(Precision + Recall)\n",
    "\n",
    "\n",
    "#### b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A+':           true  false\n",
      "positive     0      0\n",
      "negative     0      0, 'A':           true  false\n",
      "positive     0      0\n",
      "negative     0      0, 'B':           true  false\n",
      "positive     0      0\n",
      "negative     0      0, 'C':           true  false\n",
      "positive     0      0\n",
      "negative     0      0, 'D':           true  false\n",
      "positive     0      0\n",
      "negative     0      0, 'F':           true  false\n",
      "positive     0      0\n",
      "negative     0      0}\n",
      "For the label A+, precision = 1.000, recall = 1.000, f-1 = 1.000\n",
      "\n",
      "For the label A, precision = 1.000, recall = 0.778, f-1 = 0.875\n",
      "\n",
      "For the label B, precision = 0.900, recall = 1.000, f-1 = 0.947\n",
      "\n",
      "For the label C, precision = 0.778, recall = 0.933, f-1 = 0.848\n",
      "\n",
      "For the label D, precision = 1.000, recall = 0.714, f-1 = 0.833\n",
      "\n",
      "For the label F, precision = 0.714, recall = 1.000, f-1 = 0.833\n",
      "\n",
      "macro averaging scores: precision = 0.8986772486772486, recall = 0.9042328042328043, f1 = 0.8895866560340244\n"
     ]
    }
   ],
   "source": [
    "#First evaluate all the predicitons into TP, TN, FN and FP for each class\n",
    "\n",
    "#Setup dataframes for storing the TP, TN, FN and FP results\n",
    "labelAccuracy = {\"A+\":None,\"A\":None,\"B\":None,\"C\":None,\"D\":None,\"F\":None}\n",
    "\n",
    "for label in labelAccuracy.keys():\n",
    "    labelAccuracy[label] = pd.DataFrame(0, index=[\"positive\", \"negative\"], columns=[\"true\", \"false\"]) \n",
    "    \n",
    "# print(labelAccuracy)\n",
    "\n",
    "\n",
    "def add_one(label, truFal, posNeg):\n",
    "    if pd.isnull(labelAccuracy[label][truFal][posNeg]):\n",
    "        labelAccuracy[label][truFal][posNeg] = 1\n",
    "    else:\n",
    "        labelAccuracy[label][truFal][posNeg] += 1\n",
    "\n",
    "        \n",
    "def count_error_type(label, predictedGrade, actualGrade):\n",
    "    if(predictedGrade == actualGrade and predictedGrade == label):\n",
    "        add_one(label, \"true\", \"positive\")\n",
    "    elif(label != predictedGrade and label != actualGrade):\n",
    "        add_one(label, \"true\", \"negative\")\n",
    "    elif(label == predictedGrade and label != actualGrade):\n",
    "        add_one(label, \"false\", \"positive\")\n",
    "    elif(label != predictedGrade and label == actualGrade):\n",
    "        add_one(label, \"false\", \"negative\")\n",
    "    \n",
    "\n",
    "# This function should evaluate a set of predictions in terms of accuracy\n",
    "def evaluateF1(data):\n",
    "    #For each instance\n",
    "    for inst in data.iterrows():\n",
    "        \n",
    "        predictedGrade = predict_grade(inst[1])\n",
    "        actualGrade = inst[1][\"Grade\"]\n",
    "        \n",
    "        #Go through all the labels and find if it evaluated a TP, TN, FN or FP\n",
    "        for label in labelAccuracy.keys():\n",
    "            #If interesting key is correct, label as correct\n",
    "            count_error_type(label, predictedGrade, actualGrade)\n",
    "#             if(predictedGrade == \"A+\"):\n",
    "#                 print(\"Our instance = {}, predicted grade = {}, label of interest = {}, labelTFPNDict = {}\".format(actualGrade, predictedGrade, label, labelAccuracy))            \n",
    " \n",
    "    return\n",
    "\n",
    "eps = 1e-30\n",
    "\n",
    "def safe_divide(num, denom):\n",
    "    if (denom < eps):\n",
    "        return 0\n",
    "    else:\n",
    "        return num/denom\n",
    "    \n",
    "def ave(lst, index): \n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for indList in lst:\n",
    "        sum += indList[index]\n",
    "        count += 1\n",
    "    return sum/count\n",
    "        \n",
    "\n",
    "def print_func():\n",
    "    mac_ave = []\n",
    "    for key in labelAccuracy.keys():\n",
    "        theKey = key\n",
    "        la = labelAccuracy\n",
    "        \n",
    "        precision = safe_divide(la[key][\"true\"][\"positive\"],(la[key][\"true\"][\"positive\"] + la[key][\"false\"][\"positive\"]))\n",
    "        recall = safe_divide(la[key][\"true\"][\"positive\"],(la[key][\"true\"][\"positive\"] + la[key][\"false\"][\"negative\"]))\n",
    "        f1 = safe_divide((2*precision*recall),(precision + recall))\n",
    "        mac_ave.append([key, precision, recall, f1].copy())\n",
    "      \n",
    "        print(\"For the label {}, precision = {:.3f}, recall = {:.3f}, f-1 = {:.3f}\".format(key, precision, recall, f1))\n",
    "        print()\n",
    "        \n",
    "#     print(\"macro averaging scores: precision = {}, recall = {}, f1 = {}\".format((mac_ave),(mac_ave),(mac_ave)))\n",
    "    print(\"macro averaging scores: precision = {}, recall = {}, f1 = {}\".format(ave(mac_ave, 1),ave(mac_ave,2),ave(mac_ave,3)))\n",
    "        \n",
    " \n",
    "\n",
    "evaluateF1(testData)\n",
    "print_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 3: Training Strategies \n",
    "\n",
    "There are other evaluation strategies, which tend to be preferred over the hold-out strategy you implemented in Question 1.\n",
    "- a Select one such strategy, (i) describe how it works, and (ii) explain why it is preferable over hold-out evaluation. [no programming required]\n",
    "- b Implement your chosen strategy from Question 3a, and report the accuracy score(s) of your classifier under this strategy. Compare your outcomes against your accuracy score in Question 1, and explain your observations in the context of your response to question 3a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.43838862559241704. (370 successes and 474 fails)\n",
      "accuracy is 0.44974321349963314. (613 successes and 750 fails)\n",
      "accuracy is 0.4505844845908608. (848 successes and 1034 fails)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-193-dd533882e329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtempDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrawData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstartIndex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mendIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#     print(\"indexes = {}, {}. Ogsize = {}, Size now = {}\".format(startIndex, endIndex, len(rawData), len(tempDF)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-191-e6fd1c78ea3a>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(dataFrame)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         print(\"instance number {} is predicted to be = {}, actual grade = {}\".format(i, find_grade(inst[1]), inst[1][\"Grade\"]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_grade\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Grade\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"success\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-187-6629c8a924d2>\u001b[0m in \u001b[0;36mpredict_grade\u001b[1;34m(instance)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#For every potential label (A+, A, B, C, D, F), find P(label|params)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabelProbability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mlabelProbability\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m#     print(\"Calculated probabilities = {}\".format(labelProbability))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-187-6629c8a924d2>\u001b[0m in \u001b[0;36mfind_probability\u001b[1;34m(testGrade, testInst)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#Don't use the \"Grade\" column for the instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin_de_worsop\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1896\u001b[0m             \u001b[0mInfo\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m         \"\"\"\n\u001b[1;32m-> 1898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1900\u001b[0m     \u001b[1;31m# can we get a better explanation of this?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin_de_worsop\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin_de_worsop\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3949\u001b[0m         \u001b[0m_ndarray_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3950\u001b[0m         \"\"\"\n\u001b[1;32m-> 3951\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3953\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#part a)\n",
    "\n",
    "\n",
    "n = 5\n",
    "chunkSize = int(len(rawData)/n)\n",
    "\n",
    "for i in range(n):\n",
    "    startIndex = i*chunkSize\n",
    "    endIndex = startIndex + chunkSize\n",
    "    \n",
    "    #Deals with ugly divisors len(rawData)/chunkSize\n",
    "    if i == n-1:\n",
    "        endIndex = len(rawData)-1\n",
    "    \n",
    "#     tempDF = rawData.copy()\n",
    "    \n",
    "    tempDF = rawData.drop(rawData.loc[startIndex:endIndex].index, inplace=False)\n",
    "#     print(\"indexes = {}, {}. Ogsize = {}, Size now = {}\".format(startIndex, endIndex, len(rawData), len(tempDF)))\n",
    "    \n",
    "    \n",
    "    evaluate(tempDF)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (you may respond in a cell or cells below):\n",
    "\n",
    "You should respond to Question 1 and two additional questions of your choice. A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "### Question 1: Naive Bayes Concepts and Implementation\n",
    "\n",
    "- a Explain the ‘naive’ assumption underlying Naive Bayes. (1) Why is it necessary? (2) Why can it be problematic? Link your discussion to the features of the students data set. [no programming required]\n",
    "- b Implement the required functions to load the student dataset, and estimate a Naive Bayes model. Evaluate the resulting classifier using the hold-out strategy, and measure its performance using accuracy.\n",
    "- c What accuracy does your classifier achieve? Manually inspect a few instances for which your classifier made correct predictions, and some for which it predicted incorrectly, and discuss any patterns you can find.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Question 4: Model Comparison\n",
    "\n",
    "In order to understand whether a machine learning model is performing satisfactorily we typically compare its performance against alternative models. \n",
    "- a Choose one (simple) comparison model, explain (i) the workings of your chosen model, and (ii) why you chose this particular model. \n",
    "- b Implement your model of choice. How does the performance of the Naive Bayes classifier compare against your additional model? Explain your observations.\n",
    "\n",
    "### Question 5: Bias and Fairness in Student Success Prediction\n",
    "\n",
    "As machine learning practitioners, we should be aware of possible ethical considerations around the\n",
    "applications we develop. The classifier you developed in this assignment could for example be used\n",
    "to classify college applicants into admitted vs not-admitted – depending on their predicted\n",
    "grade.\n",
    "- a Discuss ethical problems which might arise in this application and lead to unfair treatment of the applicants. Link your discussion to the set of features provided in the students data set. [no programming required]\n",
    "- b Select ethically problematic features from the data set and remove them from the data set. Use your own judgment (there is no right or wrong), and document your decisions. Train your Naive Bayes classifier on the resulting data set containing only ‘unproblematic’ features. How does the performance change in comparison to the full classifier?\n",
    "- c The approach to fairness we have adopted is called “fairness through unawareness” – we simply deleted any questionable features from our data. Removing all problematic features does not guarantee a fair classifier. Can you think of reasons why removing problematic features is not enough? [no programming required]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['5', '2', '3', '4', '1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(featureFrames[22].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-41ca6fd097e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mrawData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrawData\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdfList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"student.csv\"\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "#make many df's \n",
    "#add a col to df live\n",
    "dfList = []\n",
    "rawData = load_data(path)\n",
    "for col in rawData:\n",
    "    dfList.append(Data)\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
