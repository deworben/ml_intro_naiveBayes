{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP90049 Introduction to Machine Learning, 2020 Semester 1\n",
    "-----\n",
    "## Project 1: Understanding Student Success with Naive Bayes\n",
    "-----\n",
    "###### Student Name(s):\n",
    "###### Python version:\n",
    "###### Submission deadline: 11am, Wed 22 Apr 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Project 1 submission. \n",
    "\n",
    "Marking will be applied on the five functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 is found below\n",
    "## 1) Part A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1) Part B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n",
      "  school sex address famsize Pstatus  Medu  Fedu      Mjob      Fjob  reason  \\\n",
      "0     GP   M       U     GT3       T  high  high  services   teacher    home   \n",
      "1     MS   M       R     GT3       T   mid   mid     other     other  course   \n",
      "2     GP   F       R     LE3       T   mid   mid  services  services  course   \n",
      "\n",
      "   ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "0  ...      yes       no      5        2     3    1    2      5   \n",
      "1  ...      yes       no      2        5     5    5    5      5   \n",
      "2  ...      yes       no      3        3     2    2    2      3   \n",
      "\n",
      "        absences Grade  \n",
      "0    four_to_six     B  \n",
      "1  more_than_ten     D  \n",
      "2           none     D  \n",
      "\n",
      "[3 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"student.csv\"\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "rawData = load_data(path)\n",
    "print(len(rawData))\n",
    "print(rawData.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex address famsize Pstatus  Medu  Fedu   Mjob      Fjob reason  \\\n",
      "515     MS   M       U     GT3       T   mid   low  other  services   home   \n",
      "231     GP   F       U     GT3       A  high  high  other   teacher   home   \n",
      "67      GP   F       U     GT3       T   low   low  other     other   home   \n",
      "\n",
      "     ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "515  ...       no       no      3        2     3    1    3      4   \n",
      "231  ...       no       no      4        1     4    1    1      1   \n",
      "67   ...      yes       no      5        4     4    1    1      4   \n",
      "\n",
      "         absences Grade  \n",
      "515          none     D  \n",
      "231  one_to_three     C  \n",
      "67           none     C  \n",
      "\n",
      "[3 rows x 30 columns]\n",
      "    school sex address famsize Pstatus  Medu Fedu      Mjob   Fjob  \\\n",
      "197     GP   F       U     LE3       A  high  mid   teacher  other   \n",
      "252     GP   M       U     LE3       T  high  mid  services  other   \n",
      "\n",
      "         reason  ... internet romantic famrel freetime goout Dalc Walc health  \\\n",
      "197      course  ...       no       no      4        3     2    1    1      4   \n",
      "252  reputation  ...      yes       no      5        4     2    1    2      5   \n",
      "\n",
      "        absences Grade  \n",
      "197  four_to_six     B  \n",
      "252  four_to_six     C  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This function should split a data set into a training set and hold-out test set\n",
    "def split_data(rawData):\n",
    "#     return rawData, rawData\n",
    "    return train_test_split(rawData, test_size=0.5)\n",
    "\n",
    "trainData, testData = split_data(rawData)\n",
    "print(trainData.head(3))\n",
    "print(testData.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "featureFrames = None\n",
    "CLASSES = [\"A+\", \"A\",\"B\",\"C\",\"D\",\"F\"]\n",
    "\n",
    "\n",
    "def make_grade_struct():\n",
    "    featureFrames[len(list(rawData))-1] = pd.DataFrame(columns=CLASSES, index=CLASSES)\n",
    "\n",
    "def make_data_structs():\n",
    "    global featureFrames\n",
    "    featureFrames = []\n",
    "    paramNames = []\n",
    "\n",
    "    #For each feature\n",
    "    for feature in list(rawData):\n",
    "        \n",
    "        #Find all the names of the paramaters by iterating through all data\n",
    "        for j in range(len(rawData)):\n",
    "            if str(rawData[feature][j]) not in paramNames:\n",
    "                paramNames.append(str(rawData[feature][j]))        \n",
    "        \n",
    "        #Make a dataframe to store frequency information with format:     \n",
    "        #     A+    A    B    C    D    F\n",
    "        # T  NaN  NaN  NaN  NaN  NaN  NaN\n",
    "        # A  NaN  NaN  NaN  NaN  NaN  NaN\n",
    "        \n",
    "        df = pd.DataFrame(columns=CLASSES, index=paramNames)\n",
    "        featureFrames.append(df.copy())\n",
    "\n",
    "        #Reset paramNames \n",
    "        paramNames = []\n",
    "        \n",
    "    #In case we don't see all the grade values, do this manually \n",
    "    make_grade_struct()    \n",
    "    \n",
    "def count_param_freq(data):\n",
    "    #For every feature\n",
    "    for i, feature in enumerate(list(data)):\n",
    "        \n",
    "        #Go and count the number of times each paramater resulted in what grade\n",
    "        for j in range(len(data)):\n",
    "\n",
    "            #Define the parameter feature, grade, and position in data struct\n",
    "            param = str(data[feature].iloc[j])\n",
    "            grade = data[\"Grade\"].iloc[j]\n",
    "            freqCount = featureFrames[i][grade][param]\n",
    "        \n",
    "            #Count the number of times that this parameter is seen\n",
    "            if pd.isnull(freqCount):\n",
    "                featureFrames[i][grade][param] = 1\n",
    "            else:\n",
    "                featureFrames[i][grade][param]+=1\n",
    "                \n",
    "                \n",
    "#         print(feature)\n",
    "#         print(featureFrames[i])\n",
    "#         print()\n",
    "\n",
    "            \n",
    "            \n",
    " \n",
    "\n",
    "# This function should build a supervised NB model\n",
    "def train(data):\n",
    "    make_data_structs()\n",
    "    count_param_freq(data)\n",
    "    return\n",
    "\n",
    "\n",
    "train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance number 0 is predicted to be = B, actual grade = B\n",
      "instance number 1 is predicted to be = B, actual grade = C\n",
      "instance number 2 is predicted to be = D, actual grade = C\n",
      "instance number 3 is predicted to be = B, actual grade = A\n",
      "instance number 4 is predicted to be = D, actual grade = D\n",
      "instance number 5 is predicted to be = D, actual grade = D\n",
      "instance number 6 is predicted to be = D, actual grade = B\n",
      "instance number 7 is predicted to be = D, actual grade = B\n",
      "instance number 8 is predicted to be = D, actual grade = D\n",
      "instance number 9 is predicted to be = C, actual grade = A\n",
      "instance number 10 is predicted to be = B, actual grade = C\n",
      "instance number 11 is predicted to be = D, actual grade = B\n",
      "instance number 12 is predicted to be = F, actual grade = F\n",
      "instance number 13 is predicted to be = C, actual grade = D\n",
      "instance number 14 is predicted to be = D, actual grade = D\n",
      "instance number 15 is predicted to be = D, actual grade = D\n",
      "instance number 16 is predicted to be = D, actual grade = B\n",
      "instance number 17 is predicted to be = F, actual grade = F\n",
      "instance number 18 is predicted to be = F, actual grade = F\n",
      "instance number 19 is predicted to be = D, actual grade = D\n",
      "instance number 20 is predicted to be = D, actual grade = A+\n",
      "instance number 21 is predicted to be = D, actual grade = D\n",
      "instance number 22 is predicted to be = A+, actual grade = A\n",
      "instance number 23 is predicted to be = B, actual grade = B\n",
      "instance number 24 is predicted to be = D, actual grade = D\n",
      "instance number 25 is predicted to be = D, actual grade = C\n",
      "instance number 26 is predicted to be = C, actual grade = D\n",
      "instance number 27 is predicted to be = A, actual grade = A\n",
      "instance number 28 is predicted to be = D, actual grade = D\n",
      "instance number 29 is predicted to be = A, actual grade = B\n",
      "instance number 30 is predicted to be = D, actual grade = F\n",
      "instance number 31 is predicted to be = C, actual grade = A\n",
      "instance number 32 is predicted to be = A, actual grade = C\n",
      "instance number 33 is predicted to be = C, actual grade = B\n",
      "instance number 34 is predicted to be = C, actual grade = B\n",
      "instance number 35 is predicted to be = C, actual grade = C\n",
      "instance number 36 is predicted to be = C, actual grade = C\n",
      "instance number 37 is predicted to be = C, actual grade = C\n",
      "instance number 38 is predicted to be = C, actual grade = A+\n",
      "instance number 39 is predicted to be = B, actual grade = B\n",
      "instance number 40 is predicted to be = D, actual grade = A\n",
      "instance number 41 is predicted to be = C, actual grade = C\n",
      "instance number 42 is predicted to be = C, actual grade = B\n",
      "instance number 43 is predicted to be = D, actual grade = F\n",
      "instance number 44 is predicted to be = C, actual grade = D\n",
      "instance number 45 is predicted to be = A, actual grade = A\n",
      "instance number 46 is predicted to be = B, actual grade = B\n",
      "instance number 47 is predicted to be = D, actual grade = D\n",
      "instance number 48 is predicted to be = D, actual grade = C\n",
      "instance number 49 is predicted to be = D, actual grade = B\n",
      "instance number 50 is predicted to be = C, actual grade = C\n",
      "instance number 51 is predicted to be = B, actual grade = C\n",
      "instance number 52 is predicted to be = B, actual grade = A\n",
      "instance number 53 is predicted to be = B, actual grade = F\n",
      "instance number 54 is predicted to be = D, actual grade = B\n",
      "instance number 55 is predicted to be = C, actual grade = C\n",
      "instance number 56 is predicted to be = A, actual grade = B\n",
      "instance number 57 is predicted to be = C, actual grade = A\n",
      "instance number 58 is predicted to be = F, actual grade = D\n",
      "instance number 59 is predicted to be = D, actual grade = D\n",
      "instance number 60 is predicted to be = D, actual grade = B\n",
      "instance number 61 is predicted to be = F, actual grade = C\n",
      "instance number 62 is predicted to be = F, actual grade = F\n",
      "instance number 63 is predicted to be = D, actual grade = B\n",
      "instance number 64 is predicted to be = D, actual grade = C\n",
      "instance number 65 is predicted to be = C, actual grade = D\n",
      "instance number 66 is predicted to be = D, actual grade = F\n",
      "instance number 67 is predicted to be = A, actual grade = B\n",
      "instance number 68 is predicted to be = C, actual grade = C\n",
      "instance number 69 is predicted to be = D, actual grade = D\n",
      "instance number 70 is predicted to be = D, actual grade = B\n",
      "instance number 71 is predicted to be = B, actual grade = B\n",
      "instance number 72 is predicted to be = C, actual grade = D\n",
      "instance number 73 is predicted to be = D, actual grade = F\n",
      "instance number 74 is predicted to be = D, actual grade = C\n",
      "instance number 75 is predicted to be = D, actual grade = D\n",
      "instance number 76 is predicted to be = A, actual grade = C\n",
      "instance number 77 is predicted to be = F, actual grade = D\n",
      "instance number 78 is predicted to be = C, actual grade = D\n",
      "instance number 79 is predicted to be = F, actual grade = D\n",
      "instance number 80 is predicted to be = C, actual grade = C\n",
      "instance number 81 is predicted to be = D, actual grade = D\n",
      "instance number 82 is predicted to be = D, actual grade = D\n",
      "instance number 83 is predicted to be = B, actual grade = A\n",
      "instance number 84 is predicted to be = D, actual grade = D\n",
      "instance number 85 is predicted to be = D, actual grade = F\n",
      "instance number 86 is predicted to be = B, actual grade = A+\n",
      "instance number 87 is predicted to be = B, actual grade = D\n",
      "instance number 88 is predicted to be = A, actual grade = C\n",
      "instance number 89 is predicted to be = F, actual grade = D\n",
      "instance number 90 is predicted to be = D, actual grade = D\n",
      "instance number 91 is predicted to be = A, actual grade = A+\n",
      "instance number 92 is predicted to be = D, actual grade = D\n",
      "instance number 93 is predicted to be = C, actual grade = B\n",
      "instance number 94 is predicted to be = B, actual grade = A\n",
      "instance number 95 is predicted to be = D, actual grade = D\n",
      "instance number 96 is predicted to be = C, actual grade = D\n",
      "instance number 97 is predicted to be = D, actual grade = C\n",
      "instance number 98 is predicted to be = F, actual grade = F\n",
      "instance number 99 is predicted to be = B, actual grade = C\n",
      "instance number 100 is predicted to be = C, actual grade = D\n",
      "instance number 101 is predicted to be = C, actual grade = B\n",
      "instance number 102 is predicted to be = C, actual grade = D\n",
      "instance number 103 is predicted to be = D, actual grade = B\n",
      "instance number 104 is predicted to be = D, actual grade = F\n",
      "instance number 105 is predicted to be = A, actual grade = B\n",
      "instance number 106 is predicted to be = D, actual grade = F\n",
      "instance number 107 is predicted to be = C, actual grade = D\n",
      "instance number 108 is predicted to be = C, actual grade = C\n",
      "instance number 109 is predicted to be = B, actual grade = A\n",
      "instance number 110 is predicted to be = F, actual grade = D\n",
      "instance number 111 is predicted to be = F, actual grade = F\n",
      "instance number 112 is predicted to be = D, actual grade = D\n",
      "instance number 113 is predicted to be = B, actual grade = A\n",
      "instance number 114 is predicted to be = B, actual grade = C\n",
      "instance number 115 is predicted to be = D, actual grade = B\n",
      "instance number 116 is predicted to be = D, actual grade = C\n",
      "instance number 117 is predicted to be = C, actual grade = D\n",
      "instance number 118 is predicted to be = C, actual grade = F\n",
      "instance number 119 is predicted to be = D, actual grade = D\n",
      "instance number 120 is predicted to be = C, actual grade = D\n",
      "instance number 121 is predicted to be = D, actual grade = B\n",
      "instance number 122 is predicted to be = D, actual grade = C\n",
      "instance number 123 is predicted to be = F, actual grade = F\n",
      "instance number 124 is predicted to be = D, actual grade = F\n",
      "instance number 125 is predicted to be = A, actual grade = C\n",
      "instance number 126 is predicted to be = A, actual grade = C\n",
      "instance number 127 is predicted to be = B, actual grade = B\n",
      "instance number 128 is predicted to be = B, actual grade = C\n",
      "instance number 129 is predicted to be = C, actual grade = C\n",
      "instance number 130 is predicted to be = C, actual grade = B\n",
      "instance number 131 is predicted to be = A, actual grade = A+\n",
      "instance number 132 is predicted to be = A+, actual grade = D\n",
      "instance number 133 is predicted to be = D, actual grade = D\n",
      "instance number 134 is predicted to be = B, actual grade = B\n",
      "instance number 135 is predicted to be = D, actual grade = D\n",
      "instance number 136 is predicted to be = C, actual grade = A\n",
      "instance number 137 is predicted to be = A, actual grade = B\n",
      "instance number 138 is predicted to be = F, actual grade = D\n",
      "instance number 139 is predicted to be = B, actual grade = A\n",
      "instance number 140 is predicted to be = D, actual grade = C\n",
      "instance number 141 is predicted to be = A, actual grade = A+\n",
      "instance number 142 is predicted to be = C, actual grade = B\n",
      "instance number 143 is predicted to be = D, actual grade = B\n",
      "instance number 144 is predicted to be = C, actual grade = B\n",
      "instance number 145 is predicted to be = A, actual grade = B\n",
      "instance number 146 is predicted to be = D, actual grade = C\n",
      "instance number 147 is predicted to be = B, actual grade = B\n",
      "instance number 148 is predicted to be = D, actual grade = D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance number 149 is predicted to be = D, actual grade = F\n",
      "instance number 150 is predicted to be = C, actual grade = B\n",
      "instance number 151 is predicted to be = C, actual grade = C\n",
      "instance number 152 is predicted to be = F, actual grade = F\n",
      "instance number 153 is predicted to be = F, actual grade = D\n",
      "instance number 154 is predicted to be = C, actual grade = B\n",
      "instance number 155 is predicted to be = B, actual grade = D\n",
      "instance number 156 is predicted to be = D, actual grade = F\n",
      "instance number 157 is predicted to be = C, actual grade = D\n",
      "instance number 158 is predicted to be = D, actual grade = D\n",
      "instance number 159 is predicted to be = A+, actual grade = A\n",
      "instance number 160 is predicted to be = D, actual grade = D\n",
      "instance number 161 is predicted to be = C, actual grade = A\n",
      "instance number 162 is predicted to be = D, actual grade = D\n",
      "instance number 163 is predicted to be = C, actual grade = B\n",
      "instance number 164 is predicted to be = A+, actual grade = C\n",
      "instance number 165 is predicted to be = D, actual grade = D\n",
      "instance number 166 is predicted to be = D, actual grade = C\n",
      "instance number 167 is predicted to be = D, actual grade = D\n",
      "instance number 168 is predicted to be = C, actual grade = D\n",
      "instance number 169 is predicted to be = B, actual grade = C\n",
      "instance number 170 is predicted to be = D, actual grade = F\n",
      "instance number 171 is predicted to be = D, actual grade = D\n",
      "instance number 172 is predicted to be = B, actual grade = B\n",
      "instance number 173 is predicted to be = F, actual grade = F\n",
      "instance number 174 is predicted to be = D, actual grade = F\n",
      "instance number 175 is predicted to be = D, actual grade = C\n",
      "instance number 176 is predicted to be = B, actual grade = D\n",
      "instance number 177 is predicted to be = F, actual grade = F\n",
      "instance number 178 is predicted to be = D, actual grade = F\n",
      "instance number 179 is predicted to be = C, actual grade = F\n",
      "instance number 180 is predicted to be = D, actual grade = F\n",
      "instance number 181 is predicted to be = D, actual grade = F\n",
      "instance number 182 is predicted to be = D, actual grade = F\n",
      "instance number 183 is predicted to be = F, actual grade = C\n",
      "instance number 184 is predicted to be = B, actual grade = F\n",
      "instance number 185 is predicted to be = C, actual grade = C\n",
      "instance number 186 is predicted to be = D, actual grade = D\n",
      "instance number 187 is predicted to be = A, actual grade = C\n",
      "instance number 188 is predicted to be = B, actual grade = D\n",
      "instance number 189 is predicted to be = C, actual grade = C\n",
      "instance number 190 is predicted to be = D, actual grade = D\n",
      "instance number 191 is predicted to be = D, actual grade = D\n",
      "instance number 192 is predicted to be = C, actual grade = A\n",
      "instance number 193 is predicted to be = F, actual grade = D\n",
      "instance number 194 is predicted to be = D, actual grade = D\n",
      "instance number 195 is predicted to be = B, actual grade = C\n",
      "instance number 196 is predicted to be = B, actual grade = B\n",
      "instance number 197 is predicted to be = A+, actual grade = C\n",
      "instance number 198 is predicted to be = A, actual grade = F\n",
      "instance number 199 is predicted to be = D, actual grade = F\n",
      "instance number 200 is predicted to be = B, actual grade = D\n",
      "instance number 201 is predicted to be = D, actual grade = C\n",
      "instance number 202 is predicted to be = A, actual grade = F\n",
      "instance number 203 is predicted to be = C, actual grade = D\n",
      "instance number 204 is predicted to be = D, actual grade = B\n",
      "instance number 205 is predicted to be = D, actual grade = D\n",
      "instance number 206 is predicted to be = D, actual grade = D\n",
      "instance number 207 is predicted to be = C, actual grade = C\n",
      "instance number 208 is predicted to be = B, actual grade = A\n",
      "instance number 209 is predicted to be = A, actual grade = A\n",
      "instance number 210 is predicted to be = D, actual grade = D\n",
      "instance number 211 is predicted to be = D, actual grade = B\n",
      "instance number 212 is predicted to be = B, actual grade = C\n",
      "instance number 213 is predicted to be = B, actual grade = C\n",
      "instance number 214 is predicted to be = B, actual grade = A\n",
      "instance number 215 is predicted to be = D, actual grade = C\n",
      "instance number 216 is predicted to be = C, actual grade = D\n",
      "instance number 217 is predicted to be = C, actual grade = C\n",
      "instance number 218 is predicted to be = C, actual grade = A+\n",
      "instance number 219 is predicted to be = B, actual grade = A\n",
      "instance number 220 is predicted to be = C, actual grade = A\n",
      "instance number 221 is predicted to be = C, actual grade = B\n",
      "instance number 222 is predicted to be = D, actual grade = D\n",
      "instance number 223 is predicted to be = D, actual grade = F\n",
      "instance number 224 is predicted to be = C, actual grade = F\n",
      "instance number 225 is predicted to be = C, actual grade = C\n",
      "instance number 226 is predicted to be = A, actual grade = B\n",
      "instance number 227 is predicted to be = D, actual grade = C\n",
      "instance number 228 is predicted to be = A, actual grade = B\n",
      "instance number 229 is predicted to be = A, actual grade = F\n",
      "instance number 230 is predicted to be = D, actual grade = D\n",
      "instance number 231 is predicted to be = B, actual grade = D\n",
      "instance number 232 is predicted to be = C, actual grade = C\n",
      "instance number 233 is predicted to be = C, actual grade = C\n",
      "instance number 234 is predicted to be = B, actual grade = C\n",
      "instance number 235 is predicted to be = D, actual grade = C\n",
      "instance number 236 is predicted to be = C, actual grade = C\n",
      "instance number 237 is predicted to be = F, actual grade = F\n",
      "instance number 238 is predicted to be = D, actual grade = D\n",
      "instance number 239 is predicted to be = B, actual grade = C\n",
      "instance number 240 is predicted to be = B, actual grade = B\n",
      "instance number 241 is predicted to be = D, actual grade = C\n",
      "instance number 242 is predicted to be = D, actual grade = D\n",
      "instance number 243 is predicted to be = D, actual grade = D\n",
      "instance number 244 is predicted to be = A, actual grade = B\n",
      "instance number 245 is predicted to be = F, actual grade = F\n",
      "instance number 246 is predicted to be = F, actual grade = F\n",
      "instance number 247 is predicted to be = C, actual grade = D\n",
      "instance number 248 is predicted to be = D, actual grade = D\n",
      "instance number 249 is predicted to be = A, actual grade = B\n",
      "instance number 250 is predicted to be = D, actual grade = D\n",
      "instance number 251 is predicted to be = D, actual grade = F\n",
      "instance number 252 is predicted to be = A, actual grade = D\n",
      "instance number 253 is predicted to be = D, actual grade = F\n",
      "instance number 254 is predicted to be = C, actual grade = B\n",
      "instance number 255 is predicted to be = D, actual grade = D\n",
      "instance number 256 is predicted to be = D, actual grade = F\n",
      "instance number 257 is predicted to be = F, actual grade = D\n",
      "instance number 258 is predicted to be = D, actual grade = F\n",
      "instance number 259 is predicted to be = D, actual grade = D\n",
      "instance number 260 is predicted to be = D, actual grade = D\n",
      "instance number 261 is predicted to be = B, actual grade = D\n",
      "instance number 262 is predicted to be = B, actual grade = A\n",
      "instance number 263 is predicted to be = F, actual grade = D\n",
      "instance number 264 is predicted to be = F, actual grade = D\n",
      "instance number 265 is predicted to be = F, actual grade = D\n",
      "instance number 266 is predicted to be = D, actual grade = B\n",
      "instance number 267 is predicted to be = D, actual grade = F\n",
      "instance number 268 is predicted to be = D, actual grade = A\n",
      "instance number 269 is predicted to be = D, actual grade = B\n",
      "instance number 270 is predicted to be = C, actual grade = B\n",
      "instance number 271 is predicted to be = B, actual grade = C\n",
      "instance number 272 is predicted to be = C, actual grade = A\n",
      "instance number 273 is predicted to be = C, actual grade = D\n",
      "instance number 274 is predicted to be = A, actual grade = B\n",
      "instance number 275 is predicted to be = D, actual grade = A\n",
      "instance number 276 is predicted to be = D, actual grade = D\n",
      "instance number 277 is predicted to be = C, actual grade = A+\n",
      "instance number 278 is predicted to be = D, actual grade = D\n",
      "instance number 279 is predicted to be = D, actual grade = C\n",
      "instance number 280 is predicted to be = D, actual grade = F\n",
      "instance number 281 is predicted to be = D, actual grade = D\n",
      "instance number 282 is predicted to be = D, actual grade = A\n",
      "instance number 283 is predicted to be = B, actual grade = A\n",
      "instance number 284 is predicted to be = D, actual grade = D\n",
      "instance number 285 is predicted to be = C, actual grade = F\n",
      "instance number 286 is predicted to be = D, actual grade = F\n",
      "instance number 287 is predicted to be = D, actual grade = C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance number 288 is predicted to be = F, actual grade = D\n",
      "instance number 289 is predicted to be = C, actual grade = D\n",
      "instance number 290 is predicted to be = A, actual grade = B\n",
      "instance number 291 is predicted to be = A+, actual grade = F\n",
      "instance number 292 is predicted to be = D, actual grade = D\n",
      "instance number 293 is predicted to be = A+, actual grade = D\n",
      "instance number 294 is predicted to be = C, actual grade = D\n",
      "instance number 295 is predicted to be = B, actual grade = C\n",
      "instance number 296 is predicted to be = A, actual grade = B\n",
      "instance number 297 is predicted to be = D, actual grade = B\n",
      "instance number 298 is predicted to be = D, actual grade = F\n",
      "instance number 299 is predicted to be = C, actual grade = C\n",
      "instance number 300 is predicted to be = D, actual grade = D\n",
      "instance number 301 is predicted to be = D, actual grade = F\n",
      "instance number 302 is predicted to be = C, actual grade = A\n",
      "instance number 303 is predicted to be = A, actual grade = B\n",
      "instance number 304 is predicted to be = C, actual grade = F\n",
      "instance number 305 is predicted to be = C, actual grade = B\n",
      "instance number 306 is predicted to be = B, actual grade = C\n",
      "instance number 307 is predicted to be = C, actual grade = A\n",
      "instance number 308 is predicted to be = C, actual grade = C\n",
      "instance number 309 is predicted to be = D, actual grade = D\n",
      "instance number 310 is predicted to be = D, actual grade = C\n",
      "instance number 311 is predicted to be = A, actual grade = C\n",
      "instance number 312 is predicted to be = D, actual grade = D\n",
      "instance number 313 is predicted to be = D, actual grade = C\n",
      "instance number 314 is predicted to be = D, actual grade = D\n",
      "instance number 315 is predicted to be = D, actual grade = B\n",
      "instance number 316 is predicted to be = A+, actual grade = B\n",
      "instance number 317 is predicted to be = D, actual grade = D\n",
      "instance number 318 is predicted to be = D, actual grade = B\n",
      "instance number 319 is predicted to be = D, actual grade = D\n",
      "instance number 320 is predicted to be = D, actual grade = B\n",
      "instance number 321 is predicted to be = D, actual grade = B\n",
      "instance number 322 is predicted to be = C, actual grade = A\n",
      "instance number 323 is predicted to be = D, actual grade = D\n",
      "instance number 324 is predicted to be = F, actual grade = F\n",
      "0.003076923076923077\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import random\n",
    "\n",
    "eps = None\n",
    "totTrainingRows = None\n",
    "\n",
    "\n",
    "def find_probability(testGrade, testInst):\n",
    "\n",
    "    #P(label|params) = const * p(param1|label) * p(param2|label) * ...\n",
    "    probability = 1\n",
    "    \n",
    "    #For every parameter, find the probability and update main prob\n",
    "    #for every feature name\n",
    "    for i, label in enumerate(rawData):\n",
    "        #Don't use the \"Grade\" column for the instance\n",
    "        if i == len(list(rawData))-1:\n",
    "            break\n",
    "            \n",
    "\n",
    "        # p(param1|label) = numberParam1|label / numberOfLabel\n",
    "        #Get the actual paramater we're finding the probability of\n",
    "        testParam = str(testInst[label])\n",
    "        \n",
    "        #Number of times this prameter was counted in training given the label\n",
    "        try:\n",
    "            #Try find the label, if you can't find it, or the value is null, probability *= eps\n",
    "            paramFreq = featureFrames[i][testGrade][testParam]       \n",
    "            if pd.isnull(paramFreq):\n",
    "                probability*=eps\n",
    "                continue\n",
    "        except:\n",
    "            probability*=eps\n",
    "            continue\n",
    "\n",
    "        \n",
    "        #The number of times this grade has been counted in training\n",
    "        gradeFreq = featureFrames[len(featureFrames)-1][testGrade][testGrade]            \n",
    "        \n",
    "#         print(\"Our instance where {}={}, according to main data=\\n {}, \\n has freq={}, with {} freq = {} with data= \\n {}\".format(label, testParam, featureFrames[i], paramFreq, testGrade, labelFreq, featureFrames[len(featureFrames)-1]))\n",
    "        #Update probability\n",
    "        probability *= (paramFreq/gradeFreq)\n",
    "\n",
    "    probability *= gradeFreq/totTrainingRows\n",
    "#     print(probability)\n",
    "#     print()\n",
    "\n",
    "    return probability\n",
    "\n",
    "def predict_grade(instance):\n",
    "    labelProbability = {\"A+\":0,\"A\":0,\"B\":0,\"C\":0,\"D\":0,\"F\":0}\n",
    "    \n",
    "    #For every potential label (A+, A, B, C, D, F), find P(label|params)\n",
    "    for label in labelProbability.keys():\n",
    "        labelProbability[label] = find_probability(label, instance)  \n",
    "    \n",
    "#     print(\"Calculated probabilities = {}\".format(labelProbability))\n",
    "    return max(labelProbability.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "\n",
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(data):\n",
    "    global eps\n",
    "    global totTrainingRows\n",
    "    eps = 1/len(data)\n",
    "    totTrainingRows = len(data)    \n",
    "    \n",
    "    for i, inst in enumerate(data.iterrows()):\n",
    "        print(\"instance number {} is predicted to be = {}, actual grade = {}\".format(i, predict_grade(inst[1]), inst[1][\"Grade\"]))\n",
    "    \n",
    "\n",
    "\n",
    "predict(testData)\n",
    "print(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.3292307692307692. (107 successes and 218 fails)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3292307692307692"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = None\n",
    "\n",
    "# This function should evaluate a set of predictions in terms of accuracy\n",
    "def evaluate(data):\n",
    "    global accuracy\n",
    "    accuracy = {\"success\":0, \"fail\":0}\n",
    "    for inst in data.iterrows():\n",
    "#         print(\"instance number {} is predicted to be = {}, actual grade = {}\".format(i, find_grade(inst[1]), inst[1][\"Grade\"]))\n",
    "        if(predict_grade(inst[1]) == inst[1][\"Grade\"]):\n",
    "            accuracy[\"success\"] += 1\n",
    "        else:\n",
    "            accuracy[\"fail\"] += 1\n",
    "    s = accuracy[\"success\"]\n",
    "    f = accuracy[\"fail\"]\n",
    "    print(\"accuracy is {}. ({} successes and {} fails)\".format((s/(s+f)), s, f))\n",
    "            \n",
    "    return (s/(s+f))\n",
    "\n",
    "evaluate(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.3292307692307692. (107 successes and 218 fails)\n"
     ]
    }
   ],
   "source": [
    "train(trainData)\n",
    "evaluate(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Part C\n",
    "kjnsdfknjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "### Question 2: A Closer Look at Evaluation\n",
    "\n",
    "- a You learnt in the lectures that precision, recall and f-1 measure can provide a more holistic and realistic picture of the classifier performance. (i) Explain the intuition behind accuracy, precision, recall, and F1-measure, (ii) contrast their utility, and (iii) discuss the difference between micro and macro averaging in the context of the data set. [no programming required]\n",
    "- b Compute precision, recall and f-1 measure of your model’s predictions on the test data set (1) separately for each class, and (2) as a single number using macro-averaging. Compare the results against your accuracy scores from Question 1. In the context of the student dataset, and your response to question 2a analyze the additional knowledge you gained about your classifier performance.\n",
    "\n",
    "\n",
    "\n",
    "#### a)\n",
    "Accuracy - This is the proportion of guesses we got right compared to all guesses. More formally:\n",
    "\n",
    "(True positives + True Negatives)/(True or Flase positives or negatives)\n",
    "\n",
    "\n",
    "Precision - With respect to a class that we care to measure (maybe A+ students in this example), how often is our model correct. If we really care about one label more than the others, we want to see how accurately we can predict that class. More formally:\n",
    "\n",
    "(True positives)/(True or False positives)\n",
    "\n",
    "\n",
    "Recall - How good is our model at detecting our desired class. More formally:\n",
    "\n",
    "(True positives)/(True positives + False Negatives)\n",
    "\n",
    "\n",
    "F1 measure - A combined measure of precision and recall using the harmonic mean. This is important because precision and recall are usually inversely correlated (models with higher recall have lower precisino and vice versa). It is defined:\n",
    "\n",
    "(2 * Precision*Recall)/(Precision + Recall)\n",
    "\n",
    "\n",
    "#### b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A+':           true  false\n",
      "positive     0      8\n",
      "negative   309      8, 'A':           true  false\n",
      "positive     3     27\n",
      "negative   266     29, 'B':           true  false\n",
      "positive    11     38\n",
      "negative   224     52, 'C':           true  false\n",
      "positive    21     54\n",
      "negative   203     47, 'D':           true  false\n",
      "positive    59     76\n",
      "negative   147     43, 'F':           true  false\n",
      "positive    13     15\n",
      "negative   258     39}\n",
      "For the label A+, precision = 0.000, recall = 0.000, f-1 = 0.000\n",
      "\n",
      "For the label A, precision = 0.100, recall = 0.094, f-1 = 0.097\n",
      "\n",
      "For the label B, precision = 0.224, recall = 0.175, f-1 = 0.196\n",
      "\n",
      "For the label C, precision = 0.280, recall = 0.309, f-1 = 0.294\n",
      "\n",
      "For the label D, precision = 0.437, recall = 0.578, f-1 = 0.498\n",
      "\n",
      "For the label F, precision = 0.464, recall = 0.250, f-1 = 0.325\n",
      "\n",
      "macro averaging scores: precision = 0.2509687578735198, recall = 0.23426801276065987, f1 = 0.23496655900698368\n"
     ]
    }
   ],
   "source": [
    "#First evaluate all the predicitons into TP, TN, FN and FP for each class\n",
    "\n",
    "#Setup dataframes for storing the TP, TN, FN and FP results\n",
    "labelAccuracy = {\"A+\":None,\"A\":None,\"B\":None,\"C\":None,\"D\":None,\"F\":None}\n",
    "\n",
    "for label in labelAccuracy.keys():\n",
    "    labelAccuracy[label] = pd.DataFrame(0, index=[\"positive\", \"negative\"], columns=[\"true\", \"false\"]) \n",
    "    \n",
    "# print(labelAccuracy)\n",
    "\n",
    "\n",
    "def add_one(label, truFal, posNeg):\n",
    "    if pd.isnull(labelAccuracy[label][truFal][posNeg]):\n",
    "        labelAccuracy[label][truFal][posNeg] = 1\n",
    "    else:\n",
    "        labelAccuracy[label][truFal][posNeg] += 1\n",
    "\n",
    "        \n",
    "def count_error_type(label, predictedGrade, actualGrade):\n",
    "    if(predictedGrade == actualGrade and predictedGrade == label):\n",
    "        add_one(label, \"true\", \"positive\")\n",
    "    elif(label != predictedGrade and label != actualGrade):\n",
    "        add_one(label, \"true\", \"negative\")\n",
    "    elif(label == predictedGrade and label != actualGrade):\n",
    "        add_one(label, \"false\", \"positive\")\n",
    "    elif(label != predictedGrade and label == actualGrade):\n",
    "        add_one(label, \"false\", \"negative\")\n",
    "    \n",
    "\n",
    "# This function should evaluate a set of predictions in terms of accuracy\n",
    "def evaluateF1(data):\n",
    "    #For each instance\n",
    "    for inst in data.iterrows():\n",
    "        \n",
    "        predictedGrade = predict_grade(inst[1])\n",
    "        actualGrade = inst[1][\"Grade\"]\n",
    "        \n",
    "        #Go through all the labels and find if it evaluated a TP, TN, FN or FP\n",
    "        for label in labelAccuracy.keys():\n",
    "            #If interesting key is correct, label as correct\n",
    "            count_error_type(label, predictedGrade, actualGrade)\n",
    "#             if(predictedGrade == \"A+\"):\n",
    "#                 print(\"Our instance = {}, predicted grade = {}, label of interest = {}, labelTFPNDict = {}\".format(actualGrade, predictedGrade, label, labelAccuracy))            \n",
    " \n",
    "    return\n",
    "\n",
    "eps = 1e-30\n",
    "\n",
    "def safe_divide(num, denom):\n",
    "    if (denom < eps):\n",
    "        return 0\n",
    "    else:\n",
    "        return num/denom\n",
    "    \n",
    "def ave(lst, index): \n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for indList in lst:\n",
    "        sum += indList[index]\n",
    "        count += 1\n",
    "    return sum/count\n",
    "        \n",
    "\n",
    "def print_func():\n",
    "    mac_ave = []\n",
    "    for key in labelAccuracy.keys():\n",
    "        theKey = key\n",
    "        la = labelAccuracy\n",
    "        \n",
    "        precision = safe_divide(la[key][\"true\"][\"positive\"],(la[key][\"true\"][\"positive\"] + la[key][\"false\"][\"positive\"]))\n",
    "        recall = safe_divide(la[key][\"true\"][\"positive\"],(la[key][\"true\"][\"positive\"] + la[key][\"false\"][\"negative\"]))\n",
    "        f1 = safe_divide((2*precision*recall),(precision + recall))\n",
    "        mac_ave.append([key, precision, recall, f1].copy())\n",
    "      \n",
    "        print(\"For the label {}, precision = {:.3f}, recall = {:.3f}, f-1 = {:.3f}\".format(key, precision, recall, f1))\n",
    "        print()\n",
    "        \n",
    "#     print(\"macro averaging scores: precision = {}, recall = {}, f1 = {}\".format((mac_ave),(mac_ave),(mac_ave)))\n",
    "    print(\"macro averaging scores: precision = {}, recall = {}, f1 = {}\".format(ave(mac_ave, 1),ave(mac_ave,2),ave(mac_ave,3)))\n",
    "        \n",
    " \n",
    "\n",
    "evaluateF1(testData)\n",
    "print(labelAccuracy)\n",
    "print_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 3: Training Strategies \n",
    "\n",
    "There are other evaluation strategies, which tend to be preferred over the hold-out strategy you implemented in Question 1.\n",
    "- a Select one such strategy, (i) describe how it works, and (ii) explain why it is preferable over hold-out evaluation. [no programming required]\n",
    "- b Implement your chosen strategy from Question 3a, and report the accuracy score(s) of your classifier under this strategy. Compare your outcomes against your accuracy score in Question 1, and explain your observations in the context of your response to question 3a.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1...\n",
      "accuracy is 0.3507692307692308. (114 successes and 211 fails)\n",
      "   A+   A   B   C   D   F\n",
      "GP  5  29  43  59  56  12\n",
      "MS  5   7  13  20  41  34\n",
      "\n",
      "Iteration number 2...\n",
      "accuracy is 0.3353846153846154. (109 successes and 216 fails)\n",
      "   A+   A   B   C   D   F\n",
      "GP  5  20  44  62  67  20\n",
      "MS  2   9  12  12  37  34\n",
      "\n",
      "average value = 0.34307692307692306\n"
     ]
    }
   ],
   "source": [
    "#part a)\n",
    "\n",
    "\n",
    "n = 2\n",
    "chunkSize = int(len(rawData)/n)\n",
    "accuracyLog = []\n",
    "\n",
    "for i in range(n):\n",
    "    startIndex = i*chunkSize\n",
    "    endIndex = startIndex + chunkSize\n",
    "    \n",
    "    #Deals with ugly divisors len(rawData)/chunkSize\n",
    "    if i == n-1:\n",
    "        endIndex = len(rawData)-1\n",
    "    \n",
    "#     tempDF = rawData.copy()\n",
    "    \n",
    "    tempTrainDF = rawData.drop(rawData.loc[startIndex:endIndex].index, inplace=False)\n",
    "    tempTestDF = rawData.loc[startIndex:endIndex]\n",
    "#     print(tempTestDF)\n",
    "    #     print(\"indexes = {}, {}. Ogsize = {}, Size now = {}\".format(startIndex, endIndex, len(rawData), len(tempDF)))\n",
    "    \n",
    "    print(\"Iteration number {}...\".format(i+1))\n",
    "    train(tempTrainDF)\n",
    "    accuracyLog.append(evaluate(tempTestDF))\n",
    "    print(featureFrames[0])\n",
    "    print()\n",
    "    \n",
    "\n",
    "print(\"average value = {}\".format((sum(accuracyLog)/len(accuracyLog))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (you may respond in a cell or cells below):\n",
    "\n",
    "You should respond to Question 1 and two additional questions of your choice. A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "### Question 1: Naive Bayes Concepts and Implementation\n",
    "\n",
    "- a Explain the ‘naive’ assumption underlying Naive Bayes. (1) Why is it necessary? (2) Why can it be problematic? Link your discussion to the features of the students data set. [no programming required]\n",
    "- b Implement the required functions to load the student dataset, and estimate a Naive Bayes model. Evaluate the resulting classifier using the hold-out strategy, and measure its performance using accuracy.\n",
    "- c What accuracy does your classifier achieve? Manually inspect a few instances for which your classifier made correct predictions, and some for which it predicted incorrectly, and discuss any patterns you can find.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Question 4: Model Comparison\n",
    "\n",
    "In order to understand whether a machine learning model is performing satisfactorily we typically compare its performance against alternative models. \n",
    "- a Choose one (simple) comparison model, explain (i) the workings of your chosen model, and (ii) why you chose this particular model. \n",
    "- b Implement your model of choice. How does the performance of the Naive Bayes classifier compare against your additional model? Explain your observations.\n",
    "\n",
    "### Question 5: Bias and Fairness in Student Success Prediction\n",
    "\n",
    "As machine learning practitioners, we should be aware of possible ethical considerations around the\n",
    "applications we develop. The classifier you developed in this assignment could for example be used\n",
    "to classify college applicants into admitted vs not-admitted – depending on their predicted\n",
    "grade.\n",
    "- a Discuss ethical problems which might arise in this application and lead to unfair treatment of the applicants. Link your discussion to the set of features provided in the students data set. [no programming required]\n",
    "- b Select ethically problematic features from the data set and remove them from the data set. Use your own judgment (there is no right or wrong), and document your decisions. Train your Naive Bayes classifier on the resulting data set containing only ‘unproblematic’ features. How does the performance change in comparison to the full classifier?\n",
    "- c The approach to fairness we have adopted is called “fairness through unawareness” – we simply deleted any questionable features from our data. Removing all problematic features does not guarantee a fair classifier. Can you think of reasons why removing problematic features is not enough? [no programming required]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['5', '2', '3', '4', '1'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(featureFrames[22].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-41ca6fd097e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mrawData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrawData\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdfList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"student.csv\"\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "#make many df's \n",
    "#add a col to df live\n",
    "dfList = []\n",
    "rawData = load_data(path)\n",
    "for col in rawData:\n",
    "    dfList.append(Data)\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
